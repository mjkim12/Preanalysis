---
title: "PS531 Pre-Analysis Plan"
subtitle: "Negotiating Justice: Conflict Amnesties in the Era of Accountability"
author: "Myung Jung Kim"
output:
  pdf_document:
    number_sections: yes
    fig_caption: yes
    fig_height: 8
    fig_width: 8
  word_document: default
  html_document:
    df_print: paged
fontsize: 12pt
always_allow_html: yes
bibliography: references.bib
---

```{r setup,echo=FALSE, results=FALSE, include=FALSE, cache=FALSE}
library(formatR)
library(knitr)
library(readr)
library(tidyverse)
library(car)
library(optmatch)
library(Matching)
library(RItools)
library(pscl)
library(DeclareDesign)
library(mosaic) 
library(estimatr)
library(tidyverse)
library(xtable)
library(fabricatr)
library(randomizr)
library(WeightIt)
library(cobalt)
library(arm)
library(stats)
```

# Introduction

## Research Question

"The failure to prosecute ... perpetrators such as Pol Pot, Idi Amin, and Saddam Hussein convinced the Serbs and Hutus that they could commit genocide with impunity" (@Akhavan2009, 629). To fight against such vicious cycle of injustice, the international community has been striving to end impunity for grave human rights violations. The effort culminated around 1998 with the rise of the International Criminal Court (ICC) and Universal Jurisdiction (UJ)[^1] which enabled the overriding of domestic amnesties for serious crimes against international law including genocide, war crimes, and crimes against humanity. This meant that even if a perpetrator of serious international crimes has been amnestied by his home country, he can now be prosecuted before international and foreign courts. This international legal milestone has brought the so called 'justice vs. peace' debate. One camp argues that the advent of the ICC and UJ deters future atrocities and promotes peace in the long run (@Olsen2010a, @KimSikkink2010, @SimmonsDanner2010), and some even argue that such change brought forth the transition from the "era of impunity" to "era of accountability" (@Ban2010). The other camp argues that challenge against state's granting of amnesties threatens international peace and stability as it restricts the use of amnesty as a peacemaking tool in conflicts and the traditional notion of state sovereignty (@GoldsmithKrasner2003, @SnyderVinjamuri2003, @Ginsburg2009, @Prorok2017).

[^1]: The term "Universal Jurisdiction (UJ)" refers to the idea that a national court may prosecute individuals for serious crimes against international law --such as crimes against humanity, war crimes, genocide, and torture --based on the principle that such crimes harm the international community or international order itself, which individual States may act to protect (International Justice Resource Center). To date, 163 out of the 193 UN member states that incorporate Universal Jurisdiction under national law, and they can potentially overrule amnesties for serious violations to act like an international court to prosecute international crimes (Amnesty International 2012, 2).

Yet, recent studies began to fundamentally question the need for such debate by arguing that the international legal regimes do not necessarily complicate states' use of amnesty for serious violations (hereafter, SV amnesties). They show that states not only persistently grant SV amnesties, but even increase its usage after the rise of the ICC and UJ (@Mallinder2012, 95). This raises a puzzle: why do we witness a persistent use of SV amnesties despite the advent of ICC and UJ? Some suggest that the persistence of amnesties is mainly caused by the demand factor -- the increasing demand of amnesties from perpetrators who now should feel "the credible threat [of international prosecution and] ... at least the perception of the value [of amnesty]"(@Sly2002, @Mallinder2012). Others attribute the cause to the supply factor -- states' "perceived utility [of amnesties] for ending violence" (@Jeffery2014), and "the desire to protect certain perpetrators from prosecution" (@Sikkink2012, 8). Building upon these ideas, I aim to contribute to the literature by theorizing the mechanism underlying the persistence of SV amnesties.

# Theories

This paper provides two theories on the demand factor: the amnesty-fostering theory and amnesty-deterring theory. They are distinguished by different assumptions on how rebels perceive of the threat coming from the international regimes.

## Amnesty-Fostering Theory

The "*amnesty-fostering theory*" predicts that the rebels who committed serious crimes (hereafter, culpable rebels) feel an increased threat of prosecution by the emergence of international anti-amnesty regimes (i.e., ICC and UJ) and an increased urge to request amnesties, thereby increasing the chance of negotiation for SV amnesties. This theory assumes that rebels still feel that states are able to provide amnesties because of the lack of enforcement power and executive and political will of international regimes to consistently prevent the amnestied perpetrators to go free (@Bosco2014). If amnestied, the culpable rebel may expect to stay safe at least in the home country or other neighboring states that is likely to respect the domestic amnesty more than international norms to punish him at its own yard (using UJ) or by handing him over to the ICC. If this theory holds, rebel groups that face higher risk of foreign and international prosecutions should demand more SV amnesties and hence have higher possibility of receiving SV amnesties than groups that face lower risk.

***Hypothesis 1:*** With the advent of the anti-impunity regimes, rebel groups that face greater risk of foreign and international prosecutions receive more SV amnesties than rebel groups that face lower risk of foreign and international prosecutions.

## Amnesty-Deterring Theory

The alternative theory, "*amnesty-deterring theory*," predicts the traditional belief of legal and political science scholars -- that the international anti-amnesty effort would reduce the credibility of amnesties in peace agreements (@GoldsmithKrasner2003, 48). This theory posits that the new rise of international anti-amnesty regimes deter the use of SV amnesties by creating the commitment problem between the amnesty grantors (i.e., states) and potential recipients (i.e., culpable rebels). This implies that the ICC and UJ are effective in curtailing SV amnesties as their intended functions. If this theory holds, rebel groups that face higher risk of foreign and international prosecutions should have fewer incentives to demand amnesties as the credibility of amnesties is in jeopardy. Based on the theory, I come up with my second hypothesis:

***Hypothesis 2:*** With the advent of the anti-amnesty regimes, rebel groups that face greater risk of foreign and international prosecutions receive less SV amnesties than rebel groups that face lower risk of foreign and international prosecutions.

# Research Design

The main comparison of this study is SV amnesties before and after the rise of the anti-amnesty regimes. More specifically, in empirical terms, this study hypothesizes that there is an interaction effect between the rise of the anti-amnesty regimes and a rebel group' level of risk of foreign and international prosecutions on the number of SV amnesties rebel groups receive. To test the hypotheses, I make an as-if randomized comparison using propensity score matching with observational data. I run the propensity score estimation separately for two time-periods -- before and after the rise of the anti-amnesty regimes. Research design and identification strategies are discussed in great detail below.

## Data

I use Dancy's Conflict Amnesty Data which provide information on states' issue of amnesties for civil wars from 1945 to 2014 (@Dancy2018). Since my main interest is to examine SV amnesties which usually occur once or twice in a state-rebel dyad conflict, I collapse the original data's *yearly* observations of dyad (a state-a rebel) civil conflicts into *event* observations to prevent overfitting (i.e., years of a state-rebel dyad conflict is one observation). Additionally, while the original data identify whether the amnesties cover serious crimes or not, they not identify whether the amnestied rebel groups indeed committed serious crimes. It means that some rebel groups may have received amnesties that cover a wider coverage of crimes (i.e., serious crimes) than the actual crimes that they have committed. To complement this issue, I identify rebel groups' reported involvement in serious crimes including civilian killing, child soldier, and sex crimes using the UCDP One-sided violence data set(@EckHultman2007), the Haer and Böhmelt (2017) data set (@HaerBhmelt217) and the SVAC data set (@CohenRagnhild2014) respectively. The unit of analysis in the data set is the dyad-conflict. My data have observations of 514 dyad conflicts of 105 countries.

## Variables and Measures

### Response Variable

The dependent variable is coded 1 if there has been any exchange of SV amnesties in state-rebel group dyad conflict. Data show that SV amnesties are usually exchanged once in a state-rebel dyad conflict, if there is any (86.8%). Yet, in some wars, SV amnesties were granted multiple times (at most five times), probably due to failed attempts to resolve wars even by issuing amnesties. Among 514 dyad conflicts in data, 76 cases involved with exchanging of SV amnesties.

### International Anti-amnesty Regimes (ICC, UJ)

I use year 1998 to indicate the key independent variable -- the emergence of anti-amnesty regimes. In this year, both ICC and UJ emerged together accidentally, and the 1998-cutoff is widely used in literature to indicate the transition from the era of impunity to the era of accountability (@Dancy2018, @Krcmaric2018, @Daniels2020). Using the indicator, I categorize conflicts into three types: Pre-98 wars, Post-98 wars, and Ongoing-98 wars. They represent wars that ended before 1998, wars that started after 1998, and wars that were ongoing in 1998 (i.e., that started before 1998 and ended after 1998 (e.g., 1980-2010)) respectively. Using them, I make two comparisons: First is to compare SV amnesties in *Pre98 wars* withSV amnesties in *Post98*. This comparison would be the sharpest since Pre-98 and Post-98 amnesties are clearly without and with the potential effect of the ICC and UJ respectively. Second, I can compare SV amnesties in *Pre-98 wars* with SV amnesties in *Ongoing*-98 *wars.* This comparison is also theoretically suitable because states generally grant amnesties at the end-stage of a conflict. In the actual paper, I will report both comparisons, but this pre-analysis mainly discusses the latter comparison using `Ongoing98` dummy. In the whole data set, pre-98 conflicts comprise about 59% of observations (N =295), post-98 conflicts about 27 % (N =136), and cross-98 conflicts about 13% (N = 67) (i.e., ongoing-98 conflicts (N = 203; 40%).

### Rebel's Risk of Prosecutions

To test for the conditional impact of anti-amnesty regimes, I interact the impact of anti-amnesty regimes with a measure of rebel's risk of foreign and international prosecutions. In order to measure the level of risk, I use the binary indicator of rebel's type -- whether a rebel group is a transnational rebel groups (TNRs) that operate across state borders with foreign sanctuaries or local rebel groups. This is based on my theoretical claim that TNRs face greater risk of foreign and international prosecutions than local rebel groups that operate only within its national territory. State boundaries are *de facto* lines of defense against foreign aggression (Salehyan 2007, 220), and international and foreign courts require state cooperation to apprehend suspects. For this reason, amnestied perpetrators are most likely to stay safe from arrest by foreign and international actors as long as they stay in the amnesty-granting home country. This makes local rebel groups face a lower risk of foreign or international prosecutions than TNRs. Local rebel groups have little worry whether amnesties would be overridden by the ICC or UJ. Yet, TNRs with foreign-based assets and facilities are more likely to linger outside the home country and hence confront a higher risk of arrests of external actors. Indeed, many high-ranking rebels indicted by the foreign and international courts were arrested in foreign territories, including Straton Musoni (head of the FDLR (Rwanda) arrested in Germany), Mohammed Jabbateh (a high-ranking officer of ULIMO (Liberia) arrested in the U.S.), and Charles Blé Goudé (former leader of Congrès Panafricain des Jeunes et des Patriotes (Ivory) arrested in Ghana) to name a few.

## Identification Strategy Choices

To draw a causal inference (i.e., to understand an effect of any treatment), a researcher should be able to answer what would have happened to a group that is not treated (i.e., the counterfactual). In other words, one needs a precise comparison group -- which are equivalent except for the fact that one of them received the treatment. Such setting is possible in an experimental setting in where a researcher has a control over data generation. However, this condition is difficult to be met in an observational study in which "[a] investigator cannot control the assignment of treatments to subjects" (@Rosenbaum2010, vii). Since the treated subjects and non-treated subjects are not randomly selected, the studies suffer from biases (i.e., differences between treated and control groups) before treatment. In other words, it is difficult to say whether the differences in outcome between the treated and control groups are due to "chance" or "the real treatment effect." Hence, while observational studies can draw information on key variables and their associations with its low complexity, low cost, and low ethical constraints, they are far limited in drawing a causal inference compared to a randomized experimental design.

### Propensity Score Matching

One approach to account for this limitation is to conduct a propensity score matching which enables an as-if randomized comparison by drawing a more sensible comparison group. Propensity score matching pairs subjects based on their propensity score -- the conditional probability of treatment given the observed covariates (@Rosenbaum2010, 72). By this, it effectively reduces observed biases and makes it possible to draw and compare the treated and control subjects. As the single variable summarizes relevant information in all observed control variables, one only needs to match on this scalar variable. For this reason, there is no limit on the number of covariates for adjustment, and it makes matching simpler and free from the curse of dimensionality. Most importantly, researchers can assess whether the adjustment is done enough by looking at the balance of observed covariates between control and treated units. Researcher can change model specification until a good balance is achieved. Such advantages are something unthinkable in usual regression analysis. Yet, a propensity matching strategy still has its limits. In most cases, the true propensity score is unknown, and hence it has to be estimated by modeling the receipt of treatment given observed covariates (@Imai2005). It means that bias can still arise from the process of researcher's choice of covariates in specifying the propensity score and unobserved covariates (@Rosenbaum2010, 73). Also, it discards unmatched units (@Rubin2001). Lastly, it is difficult to see the effect of matching variables on the outcome variable (@Thavaneswaran2008). Despite the limitation, this study attempts to overcome potential bias from observable covariates and reduce doubt of the result by transparently explaining the model specification and choices. 

#### The Treatment (TNRs)

I use the binary indicator of rebel group's type being transnational (`TNR`) as a treatment. The control group is the observations of local rebel groups (TNR = 0). The hypotheses predict that the treatment effect (`TNR`) on SV amnesties is only valid after the rise of the anti-amnesty regimes (post-1998). To examine the treatment effect heterogeneity, I test treatment effects for pre-1998 conflict observations (hereafter, pre98 subgroup) and post-1998 conflict observations (hereafter, post98 or ongoing98 subgroup depending on the cutoff point). I use the NSA data to distinguish whether the rebel group is a transnational. The NSA data's variable `Rebpresosts` indicates whether the rebel group operates to at least some extent outside the home country's borders. While the variable in the original dataset is trichotomous ('no,' "some," and "extensive"), I make them dichotomous. Among 414 dyads, there are 187 unique rebel groups captured in the dataset, and among them, there are 76 transnational rebel groups (TNRs) and 98 local rebel groups (no info about 13 groups). There are 201 amnesties granted to local-rebel group and 139 amnesties to TNRs.

#### PS Score Model Specification

To estimate the propensity score, I use logistic regression where I include available covariates that would statistically balance the covariates between the treated and control groups. Brookhart et al. (2006) shows that the best PS model is the model that include all predictors of outcome regardless of whether they are associated with exposure. Accordingly, I specify the propensity score using variables that may affect SV amnesties as suggested in the earlier studies. Dancy 2018 suggest that judicial independence (`judicialinde`), democratic transitions (`demtrans`), number of years at war (`yearsatwar`), territory (`territory`), intensity (`intensity`), ethnic (`ethnic`), number of other groups fighting (`numdyads`), rebel strength (`rebcap`), fighting capacity (`fightcap`), and bloody hands (`blood`) can affect the number of amnesties (@Dancy2018). Additionally, I include a variable that indicates an involvement of a third-party mediation (`mediation`) and rebel groups' actual involvement of serious violations (`sv`).

#### Matching Method

There are multiple ways of matching treated and untreated units such as nearest neighbor matching, Mahalanobis metric matching, and caliper matching. Among various options, I use the full matching sets to form weights, which are then used in the outcome analyses as demonstrated in Stuwart and Green 2008 (@StuartGreen2008). Full matching makes use of all units in the data by forming a series of matched sets in which each set has either one treated unit and one or more control units or one control units and one or more treated units (@Hansen2004). Matched sets are formed in an optimal way in that exposed units that have many comparison units with similar propensity scores will be grouped with many comparison units, whereas exposed units with few similar comparison units will be grouped with relatively fewer comparison units (@GreenStuart2014). Full matching uses original scores just to create the subclasses, not to form the weights directly (@HansenKlopfer2006), and hence it is less sensitive to the form of the propensity score model and known to form the subclasses in an optimal way (@Hansen2004). Table 1 and 2 show the structures of matched sets for Pre-98 subgroup and Ongoing98 subgroup respectively, both using full matching.

```{=tex}
\begin{table}[ht]
\centering
\begin{tabular}{rr}
  \hline
 & x \\ 
  \hline
9:1 &   1 \\ 
  8:1 &   1 \\ 
  7:1 &   1 \\ 
  6:1 &   1 \\ 
  5:1 &   1 \\ 
  3:1 &   6 \\ 
  2:1 &   4 \\ 
  1:1 &  30 \\ 
  1:2 &   7 \\ 
  1:3 &   8 \\ 
  1:4 &   6 \\ 
  1:5 &   1 \\ 
  1:10 &   2 \\ 
  1:13 &   1 \\ 
  1:14 &   1 \\ 
   \hline
\end{tabular}
\caption{Structure of Matched Sets for pre98} 
\end{table}
```

```{=tex}
\begin{table}[ht]
\centering
\begin{tabular}{rr}
  \hline
 & x \\ 
  \hline
11:1 &   1 \\ 
  6:1 &   2 \\ 
  5:1 &   1 \\ 
  2:1 &   1 \\ 
  1:1 &   7 \\ 
  1:2 &   4 \\ 
  1:3 &   2 \\ 
  1:4 &   1 \\ 
  1:6 &   1 \\ 
  1:8 &   1 \\ 
  1:9 &   1 \\ 
   \hline
\end{tabular}
\caption{Structure of Matched Sets for ongoing-98} 
\end{table}
```

#### Missing Data

Theories behind propensity score analysis assume that the covariates are fully observed (@RosenbaumRubin1983). However, in practice, missingness in the covariates is sometimes inevitably. The two common solutions to deal with the missingness are 1) imputation such as filling the mean values or zero to missing observations. and 2) omitting the observations. In this study, missing data are mainly caused by merging of multiple data sets which cover different time periods. Hence, imputing the missing values as 0 or mean value would be inappropriate. As long as missingness does not depend both on the outcome variable and treatment variable, this bias is generally small. Since there is no theoretical base to believe that the missingness in this study is related to any of these, I decide to ignore the missing data. After removing the missing data, there are 240 observations for `pre98` wars and 100 observations for `ongoing98` wars.


#### Balance of Covariates

If the propensity score is estimated properly, the distribution of covariates should be similar between treated and matched control units (@Imai2005, 295). Hence, I will judge the success of the adjustment by looking at the balance of covariate distributions in the treatment and control groups after matching. Table 3 and 4 show the differences in observed characteristics between treatment and control group of Pre-98 wars and Ongoing-98 wars before and after matching adjustments respectively. Prior to adjustment, some covariates of two groups (TNRs and local groups) exhibit significant differences with some standardized differences larger than 0.5. Such pre-treatment difference makes it difficult to induce a good comparison, and hence shows why propensity score matching can be useful in this study. After propensity score matching, all covariates have standardized difference less than 0.1. Figure 1 and 2 illustrate the `xBalance` results for Pre-98 and Ongoing-98 war observations which visualize the balance of each covariate distributions before and after matching (@HansenBowers2008). For the Pre-98 subgroup, the standardized differences of control and treatment group became closer to 0 for all covariates after matching, and hence I consider the adjustment successful. For the Ongoing-98 subgroup, the standardized differences became closer to 0 for most of covariates except `territory` and `recap` which makes the adjustment less satisfactory.

```{r Data, echo=FALSE,results=FALSE, warning=FALSE, message= FALSE}
# Load Data from Github
urlfile="https://raw.githubusercontent.com/mjkim12/Preanalysis/main/amnesty_mjk_220109.csv"

df<-read_csv(url(urlfile))

# Original Data Composition (before removing missing data)
dim(df) # 514 observations, 57 variables
unique(df$country.x) #105 countries
table(df$sum_hram) #Number of wars with SV amnesties: total 76 cases 

#Distribution of war-periods (pre98, post98, ongoing98) and SV amnesties
table(df$pre98war, df$sum_hram) #32 out of 295 dyad-conflicts involved with sv amnesties.(10.8%)
table(df$post98war, df$sum_hram) #17 out of 136 dyad-conflicts involved with sv amnesties (12.5%)
table(df$cross98war, df$sum_hram)#27 out of 67 wars involved with svamn.(40.3%)
table(df$warend_post98, df$sum_hram) #war_end_98 refers to ongoing98 (i.e., cross+post). 44 out of 203 wars involved with sv amnesties.(21.7%)

#Make some variables as binary
table(df$sum_hram) #Number of wars with SV amnesties: total 76 cases (0:422, 1: 66, 2: 6, 3: 2, 4: 1, 5:1) 
df$dummy_svamn <- ifelse(df$sum_hram>0,1,0) #making SVAmnesty into dummy

wrdf <- df %>%dplyr:: select(sum_hram, demtrans, yearsatwar, terrytory, intensity, ethnic, numdyads , rebcap, fightcap,  blood, judicialinde ,post98war, warend_post98, max_rebpresosts, mediation, mean_v2xpolyarchy,war_end_yr,)
#I excluded sv because it reduces sample size into 340 -> 100.

#Changed the variable name (max_rebpresosts is the indicator for TNR)
names(wrdf)[names(wrdf)=="max_rebpresosts"] <- "TNR"

#Removing Missing Data
sum(is.na(wrdf)) #601
wrdat <- na.omit(wrdf)
dim(wrdat) #dimension: 340, 17

table(wrdat$warend_post98) #240, 100 
table(wrdat$sum_hram)
wrdat$dummy_svamn <- ifelse(wrdat$sum_hram>0,1,0)
table(wrdat$dummy_svamn) # 287 wars w/o svamn; 53 wars with.
table(wrdat$TNR) #201 conficts vs. local, 139 conflicts vs. TNRs

#Categorizing conflicts by years of start and end yrs
df_pre98 <- wrdat[which(wrdat$post98war==0), ] #276 dyad wars
df_post98 <- wrdat[which(wrdat$post98war==1), ] #64 dyad
df_ongoing98 <- wrdat[which (wrdat$warend_post98==1), ] #100 dyad
```

```{r PS Matching for Pre-98 Data, echo=FALSE,results=FALSE, warning=FALSE, message=FALSE}
# Create linear predictors for pre-98 data
df_pre98_2 <- df_pre98

glm_ps_pre98  <-glm(TNR ~ judicialinde + demtrans +yearsatwar + terrytory+ intensity + ethnic + numdyads +rebcap + fightcap + blood+ mediation, data = df_pre98_2, family = binomial())

pscore_pre98 <- predict(glm_ps_pre98, type = "response")

# Make distance matrices
psdist_pre98 <-match_on(TNR~ pscore_pre98, data=df_pre98_2)

# Fullmatching 
fm1_pre98 <- fullmatch(psdist_pre98, data = df_pre98_2)
fm1_pre98_summary <- summary(fm1_pre98, data = df_pre98_2, min.controls = 0, max.controls = Inf)
fm1_pre98_summary

#Effective sample size 93

#xtable(fm1_pre98_summary$matched.set.structures, caption = "Structure of Matched Sets for pre98")
```



```{=tex}
\begin{table}[ht]
\caption{Differences in Observed Characteristics between Treatment and Control Group Before and After Matching Adjustment for Pre-98 Wars} 
\centering
\begin{tabular}{lrrrrrrrrrrrrrr}
  \hline
<Before> & TNR=0 & TNR=1 & adj.diff & adj.diff.null.sd & std.diff & z &  \\ 
  \hline
judicialinde & 0.24 & 0.28 & 0.04 & 0.03 & 0.18 & 1.49 & \\ 
  demtrans & 0.10 & 0.15 & 0.05 & 0.04 & 0.16 & 1.33 & \\ 
  yearsatwar & 2.77 & 6.73 & 3.95 & 0.67 & 0.76 & 5.88 & *** & \\ 
  terrytory & 0.21 & 0.41 & 0.20 & 0.06 & 0.44 & 3.52 & *** &  \\ 
  intensity & 0.50 & 0.66 & 0.16 & 0.06 & 0.34 & 2.73 & **  &  \\ 
  ethnic & 0.06 & 0.08 & 0.02 & 0.03 & 0.08 & 0.67 &  \\ 
  numdyads & 1.72 & 1.58 & -0.14 & 0.13 & -0.13 & -1.03 &    \\ 
  rebcap & -0.94 & -1.23 & -0.29 & 0.12 & -0.31 & -2.55 & *   &   \\ 
  fightcap & 0.61 & 0.30 & -0.31 & 0.07 & -0.53 & -4.21 & ***  &     \\ 
  blood & 0.12 & 0.26 & 0.15 & 0.05 & 0.38 & 3.10 & **  &     \\ 
  mediation & 0.08 & 0.15 & 0.06 & 0.04 & 0.20 & 1.67 & .    &     \\ 
   \hline
<After>& TNR=0 & TNR=1 & adj.diff & adj.diff.null.sd & std.diff & z & \\ 
  \hline
judicialinde & 0.26 & 0.25 & -0.01 & 0.03 & -0.04 & -0.28 &  \\
  demtrans & 0.10 & 0.09 & -0.01 & 0.05 & -0.03 & -0.21 &   \\
    yearsatwar & 4.10 & 4.22 & 0.12 & 0.35 & 0.02 & 0.35 &     \\
  terrytory &  0.32 & 0.30 & -0.02 & 0.07 & -0.06 & -0.38 &  \\
    intensity & 0.58 & 0.59 & 0.00 & 0.07 & 0.01 & 0.06 &    \\
    ethnic &   0.08 & 0.08 & -0.01 & 0.04 & -0.03 & -0.16 &    \\
      numdyads &  1.61 & 1.71 & 0.10 & 0.15 & 0.09 & 0.65 &    \\
        rebcap &  -1.15 & -1.15 & -0.01 & 0.12 & -0.01 & -0.06 &    \\
          fightcap & 0.43 & 0.41 & -0.01 & 0.06 & -0.02 & -0.18 &    \\
          blood & 0.17 & 0.19 & 0.03 & 0.05 & 0.07 & 0.55 &    \\
            mediation & 0.12 & 0.14 & 0.02 & 0.05 & 0.08 & 0.52 &    \\
            \hline   
\end{tabular}
\end{table}
```

```{=tex}
\begin{table}[ht]
\caption{Differences in Observed Characteristics between Treatment and Control Group Before and After Matching Adjustment for Ongoing-98 Wars} 
\centering
\begin{tabular}{lrrrrrrrrrrrrrr}
  \hline
<Before> & TNR=0 & TNR=1 & adj.diff & adj.diff.null.sd & std.diff & z &  \\ 
  \hline
judicialinde & 0.32 & 0.25 & -0.08 & 0.05 & -0.30 & -1.51 &      \\ 
  demtrans & 0.08 & 0.17 & 0.09 & 0.07 & 0.29 & 1.45 &     \\ 
  yearsatwar & 2.00 & 5.79 & 3.79 & 0.97 & 0.84 & 3.89 & *** &    \\ 
  terrytory & 0.32 & 0.30 & -0.02 & 0.09 & -0.05 & -0.25 &    \\ 
  intensity & 0.47 & 0.74 & 0.28 & 0.09 & 0.61 & 2.92 & **  &     \\ 
  ethnic & 0.06 & 0.09 & 0.03 & 0.05 & 0.11 & 0.55 &     \\ 
  numdyads & 1.90 & 1.70 & -0.20 & 0.20 & -0.20 & -1.00 &       \\ 
  rebcap & -1.25 & -1.26 & -0.01 & 0.13 & -0.01 & -0.07 &         \\ 
  fightcap & 0.36 & 0.32 & -0.04 & 0.10 & -0.08 & -0.38 &      \\ 
  blood & 0.43 & 0.62 & 0.18 & 0.10 & 0.37 & 1.82 &     \\ 
  mediation & 0.36 & 0.47 & 0.11 & 0.10 & 0.22 & 1.11 &       \\ 
   \hline
<After>& TNR=0 & TNR=1 & adj.diff & adj.diff.null.sd & std.diff & z & \\ 
  \hline
  judicialinde & 0.28 & 0.29 & 0.01 & 0.06 & 0.02 & 0.09 &  \\
 demtrans   & 0.06 & 0.06 & -0.00 & 0.08 & -0.01 & -0.05 &   \\
  yearsatwar & 2.65 & 2.88 & 0.23 & 0.56 & 0.05 & 0.41 &  \\
 terrytory   & 0.20 & 0.29 & 0.08 & 0.11 & 0.18 & 0.75 &    \\
  intensity & 0.64 & 0.61 & -0.03 & 0.09 & -0.07 & -0.33 &\\
 ethnic & 0.05 & 0.06 & 0.02 & 0.07 & 0.06 & 0.25 &     \\
  numdyads & 1.96 & 1.77 & -0.19 & 0.23 & -0.18 & -0.82 & \\ 
    rebcap &  -1.33 & -1.40 & -0.07 & 0.17 & -0.10 & -0.42 &\\   
    fightcap & 0.36 & 0.29 & -0.07 & 0.13 & -0.14 & -0.56 &   \\
    blood & 0.51 & 0.45 & -0.06 & 0.13 & -0.13 & -0.49 &  \\
   mediation  & 0.44 & 0.36 & -0.08 & 0.13 & -0.16 & -0.61 &  \\
      \hline
\end{tabular}
\end{table}
```

```{r (optional) Rank-Based Mahalanobis distance for Pre-98 Data, eval = FALSE, echo=FALSE,results=FALSE,warning=FALSE, message=FALSE}

#I tried mahalanobis distance matching, but propensity score with fullmatching produced a better matching.

##############  Rank-Based Mahalanobis distance ####
mhdist <- match_on(TNR ~ judicialinde + demtrans +yearsatwar + terrytory+ intensity + ethnic + numdyads +rebcap + fightcap + blood+ mediation, data = df_pre98_2, method = "rank_mahalanobis")
fm22 <- fullmatch(mhdist, data = df_pre98_2)
fm22sum <- summary(fm22, data = df_pre98_2, min.controls = 0, max.controls = Inf)

# Add matched set indicators back to data
df_pre98_2$fm22 <- NULL
df_pre98_2[names(fm22), "fm22"] <- fm22

## Balance test to see if I "adjusted enough"
xb22 <- xBalance(TNR ~ judicialinde + demtrans +yearsatwar + terrytory+ intensity + ethnic + numdyads +rebcap + fightcap + blood+ mediation, strata = list(raw = NULL, fm22 = ~fm22), data = df_pre98_2, report = c("std.diffs", "z.scores", "adj.means","adj.mean.diffs", "chisquare.test", "p.values"))
#plot(xb22)## Balance is worse than fullmatching 

```


```{r PS Matching for Ongoing-98 Data, echo=FALSE,results=FALSE,warning=FALSE,message=FALSE}
############## Ongoing98 ###############
# Create linear predictors for ongoing-98 data
df_ongoing98_2<-df_ongoing98

glm_ps_ongoing98 <- 
  glm(TNR ~ judicialinde + demtrans +yearsatwar + terrytory+ intensity + ethnic + numdyads +rebcap + fightcap + blood+ mediation, data = df_ongoing98_2, family = binomial())

pscore_ongoing98 <- predict(glm_ps_ongoing98, type = "response")

# Make distance matrices
psdist_ongoing98 <-match_on(TNR~ pscore_ongoing98,data=df_ongoing98_2)

# Fullmatching 
fm1_ongoing98 <- fullmatch(psdist_ongoing98, data = df_ongoing98)

fm1_ongoing98_summary <- summary(fm1_ongoing98, data = df_ongoing98, min.controls = 0, max.controls = Inf)
#There are 30.5 effective sample size

xtable(fm1_ongoing98_summary$matched.set.structures, caption = "Structure of Matched Sets for ongoing-98")

df_ongoing98$fm1_ongoing98 <- NULL
df_ongoing98[names(fm1_ongoing98),"fm1_ongoing98"] <- fm1_ongoing98
```

```{r xbalance for Pre98, results='asis', out.width='0.7\\linewidth', fig.show='asis', fig.asp=0.5, fig.ncol = 1, fig.cap="\\label{fig:xbal1} Balance Test for Pre-98", fig.align = "center", echo=FALSE, results=TRUE, message=FALSE, warning=FALSE}
#Run xBalance to assess the balance properties of the match
xb1_pre98 <- xBalance(TNR ~ judicialinde + demtrans +yearsatwar + terrytory+ intensity + ethnic + numdyads +rebcap + fightcap + blood+ mediation, 
               strata = list(raw=NULL, fm1_pre98 = ~fm1_pre98),
               data = df_pre98_2,
               report = "all")

plot(xb1_pre98, main="Pre-98 Xbalance Result")

#xtable(xb1_pre98, caption = "Balanced Treatment and Control Groups")
```

```{r Balance_Test_2, results='asis', out.width='0.7\\linewidth', fig.show='asis', fig.asp=0.5, fig.ncol = 1, fig.cap="\\label{fig:xbal2} Balance Test for Ongoing-98", fig.align = "center", echo=FALSE, results=TRUE,message=FALSE}

#Run xBalance to assess the balance properties of the match
xb1_ongoing98 <- xBalance(TNR ~ judicialinde + demtrans +yearsatwar + terrytory+ intensity + ethnic + numdyads +rebcap + fightcap + blood+ mediation,
               strata = list(raw=NULL, fm1_ongoing98 = ~fm1_ongoing98),
               data = df_ongoing98,
               report = "all")

plot(xb1_ongoing98, main="Ongoing-98 Xbalance Result") 

#xtable(xb1_ongoing98, caption = "Balanced Treatment and Control Groups 2")
```

### Test Statistics for Matched Set

#### Performance of the Tests

I test the treatment effect (TNR) on the number of SV amnesties for the treatment and control group using a t-test.  


I will use a two-way analysis of variance (ANOVA) test which is utilized to observe the interaction between the two factors and tests the effect of two factors at the same time.

Family-wise error rate (FWER) is the probability of making one or more false discoveries, or type 1 errors (i.e., incorrectly rejecting the null hypothesis when the null hypothesis is true). This is usually inflated when performing multiple hypotheses tests. In this case, p-value has to be adjusted using Bonferroni correction or adjusting false discovery rate. However, this study does not involve any multiple testing. Also, I collapse all the yearly observations into country-event, so there is little concern with overfitting issue. Hence, I will judge the performance of tests by looking at the false positive rate and power.

#### [False Positive Rate and power]{.smallcaps}

The power of a test is denoted by "(1-$\beta$)", and it is the probability of a true positive or the "probability of avoiding a false negative." It ranges from 0 to 1, and as the power increases, the probability of making type II error (false negative) decreases. A false positive rate is the probability of a type I error.

Table 5 shows powers and false positive rates using two different estimators for Pre- and Ongoing-98 data sets. Here, I show the `lm_robust` and `lm` estimator not propensity score matching OLS, since I can easily compare the model using DeclareDesign. Both are based on 0.05 thresholds for p-value (i.e., power = mean(p.value \<0.05); the same for false positive rates) and are based on 500 times of simulations.

The powers of the estimators are both very low--all four power values are less than 0.1. It indicates that these models are likely to cause a high false negative. The false positive rates are also low--all less than 0.1. It indicates that the two models are less likely to cause type I error. The low power could be caused due to frequent zero outcome variables or due to the change of outcome variable as a binary outcome.

```{r DeclareDesign PRE-98, echo=FALSE,message=FALSE, warning=FALSE}

######################### DeclareDesign PRE-98 ####################

#Matched dataset

pop_pre98_2 <- declare_population(df_pre98) #fm1_pre98

pot.outcome_pre <- declare_potential_outcomes(Y ~ 0.02*Z + dummy_svamn)

estimand_pre <- declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0))

assignment_pre <- declare_assignment(m=50, label="Z")

reveal_pre <- declare_reveal(Y,Z)

samp_pre <- declare_sampling(n=100)

estimator_pre1 <- declare_estimator(Y~ max_rebpresosts,
                                model = lm_robust,
                                term = 'TNR',
                                inquiry = 'ATE',
                                label = "lm_robust")


estimator_pre2 <- declare_estimator(Y~ max_rebpresosts + mediation+ judicialinde + demtrans +yearsatwar + terrytory + intensity + ethnic + numdyads +rebcap + fightcap +  blood,
                                model = lm,
                                term = 'TNR',
                                inquiry = 'ATE',
                                label = "lm")


design_pre1 <- pop_pre98_2 +pot.outcome_pre+ estimand_pre +assignment_pre + reveal_pre + samp_pre+ estimator_pre1

design_pre2 <- pop_pre98_2 +pot.outcome_pre+ estimand_pre +assignment_pre + reveal_pre + samp_pre+estimator_pre2

#diagnose1  <- diagnose_design(design_pre1 ,design_pre2)

#xtable(head(diagnose1$diagnosands_df[,c(3,5,6, 7,8, 9,10)]))
```

```{r DeclareDesign Ongoing-98 , echo=FALSE,message=FALSE, warning=FALSE}

######################### DeclareDesign POST 98 ####################

#Declare Population
pop_ongoing98_2 <- declare_population(df_ongoing98)  #fm1_ongoing98

pot.outcome_post <- declare_potential_outcomes(Y ~ -0.01*Z + dummy_svamn)

estimand_post <- declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0))

assignment_post <- declare_assignment(m=50, label="Z")

reveal_post <- declare_reveal(Y,Z)

samp_post <- declare_sampling(n=100)

estimator_post1 <- declare_estimator(Y~ max_rebpresosts,
                                model = lm_robust,
                                term = 'TNR',
                                inquiry = 'ATE',
                                label = "lm_robust")


estimator_post2 <- declare_estimator(Y~ max_rebpresosts+ mediation+ judicialinde + demtrans +yearsatwar + terrytory + intensity + ethnic + numdyads +rebcap + fightcap +  blood,
                                model = lm,
                                term = 'TNR',
                                inquiry = 'ATE',
                                label = "lm")


design_post1 <- pop_ongoing98_2 +pot.outcome_post+ estimand_post +assignment_post + reveal_post + samp_post+ estimator_post1


design_post2 <-pop_ongoing98_2 +pot.outcome_post+ estimand_post +assignment_post + reveal_post + samp_post+ estimator_post2


#diagnose1_post  <- diagnose_design(design_post1 ,design_post2)
#xtable(head(diagnose1_post$diagnosands_df[,c(3,5,6, 7,8, 9,10)]))
```

```{r Power and False Positive Rate, echo=FALSE, message=FALSE, warning=FALSE}
#design_pre <-diagnose_design(design_pre1, design_pre2, diagnosands = declare_diagnosands(power = mean(p.value <= 0.05), false_positive_rate = mean(p.value <= 0.05)))

#design_post <-diagnose_design(design_post1, design_post2, diagnosands = declare_diagnosands(power = mean(p.value <= 0.05), false_positive_rate = mean(p.value <= 0.05)))

#xtable(head(design_pre$diagnosands_df[,c(3,5,6,7)]))
#xtable(head(design_post$diagnosands_df[,c(3,5,6,7)]))
```

```{=tex}
\begin{table}[ht]
\centering
\caption{Power and False Positive Rates}
\begin{tabular}{rlrrr}
  \hline
 & estimator\_label & power & se(power) & false\_positive\_rate \\ 
  \hline
1 & lm\_robust & 0.08 & 0.01 & 0.08 \\ 
  2 & lm & 0.04 & 0.01 & 0.04 \\ 
  \hline
2 & lm\_robust & 0.00 & 0.00 & 0.00 \\ 
  2 & lm & 0.06 & 0.01 & 0.06 \\ 
   \hline
\end{tabular}
\end{table}
```

## Estimators and Estimand

Based on the information presented in Table 5 and 6, and considering the benefit of keeping the treatment (`democracy index`) as continuous variable, I will use `lm_robust` as the statistical estimators. As seen in Table 1, this observational study suffers bias from background confounders. In order to tackle this issue, adjustment for covariate is very critical. While propensity score matching would be a great way to overcome the problem, the nature of outcome variable in this study makes it difficult to use the matching strategy. `lm_robust` has efficiency in large samples and low bias in small samples as well as similarities to design-based randomization estimators (Samii and Aronow 2012).

The question of interest in this study is whether being democratic makes the country grant less SV amnesties compared to authoritarain regimes. Also, the study predicts such pattern more or only conspicous after 1998. In this sense, the target of estimation (estimand) is the difference in differences of the treatment effect or the interaction effect between Post-98 and democracy variables. In this pre-analysis plan, however, my estimand is the average treatment effect (`democracy`).

```{r, echo = FALSE, warning=FALSE, results= FALSE}
library(pscl)
#ALL Propensity Score#
wrdat_zero <- wrdat
#glm_ps <-   glm(max_rebpresosts ~ mediation+ judicialinde + demtrans +yearsatwar + terrytory + intensity + ethnic + numdyads +rebcap + fightcap +  blood + sv, data = wrdat_zero, family = binomial())

#pscore <- predict(glm_ps, type = "response")
#psdist <-match_on(max_rebpresosts~ pscore,data=wrdat_zero)
#fm_all <- fullmatch(psdist, data = wrdat_zero)
#fm_summary <- summary(fm_all, data = wrdat_zero, min.controls = 0, max.controls = Inf)

#ps into the dataset
#wrdat_zero$fm_all <- NULL
#wrdat_zero[names(fm_all),"fm_all"] <- fm_all
#head(wrdat_zero)
```

[11. Explain how you will judge the performance of those estimators (especially bias and MSE)? (1 paragraph)]{.smallcaps}

The performance of estimators can be evaluated by looking at characteristics like the bias, consistency, coverage, and mean squared error (MSE). The RMSE (Root Mean Squared Error) is the standard deviation of the residuals that measures how well the data values fit the line of best fit. Unbiased estimator means that the estimator or test statistic is accurate to approximate the parameter. Lastly, coverage rates refer to the coverage probability of the confidence intervals. The covarge probability shows how often we obtain a confidence interval that contains the true population parameter if we were to repeat the entire sampling and analysis process. I will judge the performance of estimators using bootstrapping (i.e., resampling with replacement).

[12. Show and explain how your estimator performs in regards those properties (at least bias and MSE). (2--4 paragraphs)]{.smallcaps}

For convenience, when feasible, I use the `diagnose_design` function in `DeclareDesign` to generate a table showing the characteristics discussed in 11. Table 6 shows the diagnose for estimators using two different estimators and each with 500 simulations. Biases are generally low--0.01 or below. Since bias is close to zero, it indicates that the estimators for the treatment coefficients are unbiased.Also, the RMSEs are below 0.2 under both estimators. It means that the data values do not deviate much from the fitted line.

```{r echo=FALSE,results=FALSE,warning=FALSE, message=FALSE}
#diagnose1  <- diagnose_design(design_pre1 ,design_pre2)
#diagnose1_post  <- diagnose_design(design_post1 ,design_post2)

#xtable(head(diagnose1$diagnosands_df[,c(3,6,7,9,10)]))
#xtable(head(diagnose1_post$diagnosands_df[,c(3,6,7,9,10)]))
```

```{=tex}
\begin{table}[ht]
\centering
\caption{Diagnosing Estimators} 
\begin{tabular}{rlrrrr}
  \hline
 & estimator\_label & bias & rmse & power & coverage \\ 
  \hline
1 & Pre-LM & -0.07 & 0.07 & 0.00 & 1.00 \\ 
   \hline
2 & Pre-GLM & -0.28 & 0.28 & 0.00 & 1.00 \\ 
  \hline
3 & Post-LM & 0.16 & 0.16 & 0.00 & 1.00 \\ 
   \hline
4 & Post-GLM & 0.99 & 0.99 & 0.00 & 1.00 \\ 
   \hline
\end{tabular}
\end{table}
```
```{=tex}
\begin{table}[ht]
\centering
\caption{Diagnosing Estimators}
\begin{tabular}{rlrrrr}
  \hline
 & estimator\_label & se(bias) & rmse & power & se(power) \\ 
  \hline
1 & lm\_robust & 0.01 & 0.11 & 0.08 & 0.01 \\ 
  2 & lm & 0.01 & 0.18 & 0.02 & 0.01 \\ 
   \hline
1 & lm\_robust & 0.00 & 0.06 & 0.00 & 0.00 \\ 
  2 & lm & 0.01 & 0.19 & 0.04 & 0.01 \\ 
   \hline
\end{tabular}
\end{table}
```
[13. Make one mock figure or table of the kind you plan to make when you use the actual outcome.]{.smallcaps}

Using fake data, I show a mock figure which shows the real data values in black, and the fitted values of the lm_robust model in red. I use propensity score matching and fixed effects to see the number of SV amnesties by democracy score. This figure shows that the actual data points are below the predicted line is above -- which means that democratic countries grant more sv amnesties. This is the opposite direction of what the theory is predicting (the figure here does not show the interaction effect).Hence, if the actual study exhibit similar figure, it would mean that the theory has weak statistical evidence.

```{r Mock Figure,echo=FALSE,results=FALSE,warning=FALSE, message=FALSE }
#fakedata <- draw_data(design_pre1)
#fakedata$sum_hram

#ALL Propensity Score#
#glm_ps <-  glm(DEM ~ judicialinde +yearsatwar + numdyads + ethnic + sv, data = wrdat, family = binomial())

#pscore <- predict(glm_ps, type = "response")
#psdist <-match_on(DEM~ pscore,data=wrdat)
#fm_all <- fullmatch(psdist, data = wrdat)
#fm_summary <- summary(fm_all, data = wrdat, min.controls = 0, max.controls = Inf)

###lm_robust
#model1 <-lm_robust(sum_hram ~ mean_v2xpolyarchy, fixed_effects = ~fm_all, data = wrdat)

#plot(wrdat$mean_v2xpolyarchy[wrdat$warend_post98==0],     wrdat$sum_hram[wrdat$warend_post98==0],    xlab="Level of Democracy",   ylab = "Number of SV Amnesties", ylim = c(0,1.2),     main = "M4")
#abline(plot(model1$fitted.values, col = 2))

```

```{r PRE98 , echo=FALSE,results=FALSE,message=FALSE,warning=FALSE}
#df_pre98_2<-df_pre98

#initialate <- mean(df_pre98_2$sum_hram[df_pre98_2$DEM == 1]) - mean(df_pre98_2$sum_hram[df_pre98_2$DEM == 0])

library(arm)
#balfmla <- lm(DEM ~ judicialinde +yearsatwar + numdyads + ethnic + sv, data = df_pre98_2)

## Bayes Generalized Linear Model
#glm2 <- bayesglm(balfmla, data = df_pre98_2, family = binomial)
#boxplot(glm2,
#main = "", names = c("Control", "Treatment"),
#xlab = ""
#)
## create linear predictors
#pscores2 <- predict(glm2)

## make distance matrices
#psdist_2 <- match_on(DEM ~ pscores2, data = df_pre98_2)
#as.matrix(psdist)[1:5,1:5]

## Rank-Based Mahalanobis distance
#mhdist <- match_on(DEM ~ judicialinde +yearsatwar + numdyads + ethnic + sv, data = df_pre98_2, method = "rank_mahalanobis")
#fm22 <- fullmatch(mhdist, data = df_pre98_2)
#fm22sum <- summary(fm22, data = df_pre98_2, min.controls = 0, max.controls = Inf)

## Add matched set indicators back to data
#df_pre98_2$fm22 <- NULL
#df_pre98_2[names(fm22), "fm22"] <- fm22

## Balance test to see if I "adjusted enough"
#xb22 <- xBalance(DEM ~ judicialinde +yearsatwar + numdyads + ethnic + sv, strata = list(raw = NULL, fm22 = ~fm22), data = df_pre98_2,report = c("std.diffs", "z.scores", "adj.means","adj.mean.diffs", "chisquare.test", "p.values"))
#plot(xb22)

## What is the biggest difference within set.
#diffswithinsets<-df_pre98_2 %>% group_by(fm22) %>% summarize(meandiff = mean(sum_hram[DEM==1]) - mean(sum_hram[DEM==0]))
#summary(diffswithinsets$meandiff)

#DIFF PRE MATCHING
#with(df_pre98_2, mean(sum_hram[DEM==1]) - mean(sum_hram[DEM==0]))
## What are the distances like? 
#tmp2 = df_pre98_2$sum_hram
#names(tmp2) <- rownames(df_pre98_2)
#absdist2 <- match_on(tmp2, z = df_pre98_2$DEM)
#qtl2 <- quantile(as.vector(absdist2),seq(0,1,.1))

##declare population
#pop_pre98_2 <- declare_population(df_pre98_2)

## declare estimator
#estimator22 <- declare_estimator(sum_hram~DEM+judicialinde + yearsatwar + numdyads + ethnic + sv,                                model = lm,                                term = 'DEM',                                estimand = 'DEM',                                label = "OLS")

##declare estimand
#make_estimands22 <- function(data){    bs <- coef(lm(sum_hram~DEM, data=df_pre98_2))    return(data.frame(estimand_label= 'DEM',               estimand=bs['DEM'],               stringsAsFactors = FALSE))}
#estimand22 <- declare_inquiry(handler=make_estimands22,                            label="Pop_Relationships")

#design1_plus_estimands22 <- pop_pre98_2 + estimand22
#kable(estimand1(df_pre98_2), caption = "Estimands 22")

#design_full22 <- design1_plus_estimands22 +  estimator22

#run_design(design_full22)
```

```{r ongoing98, echo =FALSE,message=FALSE, results=FALSE, warning=FALSE}
#df2_ongoing98 <-df_ongoing98

#initialate <- mean(df2_ongoing98$sum_hram[df2_ongoing98$DEM == 1]) - mean(df2_ongoing98$sum_hram[df2_ongoing98$DEM == 0])

#balfmla_33 <- lm(DEM ~ judicialinde +yearsatwar + numdyads + ethnic + sv, data = df2_ongoing98)

## Bayes Generalized Linear Model
#glm3 <- bayesglm(balfmla_33, data = df2_ongoing98, family = binomial)
#boxplot(glm3,main = "", names = c("Control", "Treatment"), xlab = "")
## create linear predictors
#pscores3 <- predict(glm3)

## make distance matrices
#psdist_3 <- match_on(DEM ~ pscores3, data = df2_ongoing98)
#as.matrix(psdist)[1:5,1:5]

## Rank-Based Mahalanobis distance
#mhdist_3 <- match_on(DEM ~ judicialinde +yearsatwar + numdyads + ethnic + sv, data = df2_ongoing98, method = "rank_mahalanobis")
#fm33 <- fullmatch(mhdist_3, data = df2_ongoing98)
#fm33sum <- summary(fm33, data = df2_ongoing98, min.controls = 0, max.controls = Inf)

## Add matched set indicators back to data
#df2_ongoing98$fm33 <- NULL
#df2_ongoing98[names(fm33), "fm33"] <- fm33

## Balance test to see if I "adjusted enough"
#xb33 <- xBalance(DEM ~ judicialinde +yearsatwar + numdyads + ethnic + sv,strata = list(raw = NULL, fm33 = ~fm33),data = df2_ongoing98,report = c("std.diffs", "z.scores", "adj.means","adj.mean.diffs", "chisquare.test", "p.values"))
#plot(xb33)

## What is the biggest difference within set.
#diffswithinsets<-df_pre98_2 %>% group_by(fm22) %>% summarize(meandiff = mean(sum_hram[DEM==1]) - mean(sum_hram[DEM==0]))
#summary(diffswithinsets$meandiff)

##DIFF PRE MATCHING
#with(df_pre98_2, mean(sum_hram[DEM==1]) - mean(sum_hram[DEM==0]))
## What are the distances like? 
#tmp2 = df_pre98_2$sum_hram
#names(tmp2) <- rownames(df_pre98_2)
#absdist2 <- match_on(tmp2, z = df_pre98_2$DEM)
#qtl2 <- quantile(as.vector(absdist2),seq(0,1,.1))


## declare estimator
#estimator22 <- declare_estimator(sum_hram~DEM+judicialinde + yearsatwar + numdyads + ethnic + sv,        model = lm,  term = 'DEM',         estimand = 'DEM',    label = "OLS")

###declare estimand
#make_estimands22 <- function(data){    bs <- coef(lm(sum_hram~DEM, data=df_pre98_2))    return(data.frame(estimand_label= 'DEM',               estimand=bs['DEM'],               stringsAsFactors = FALSE))}
#estimand22 <- declare_inquiry(handler=make_estimands22,                            label="Pop_Relationships")
#pop_pre98_2 <- declare_population(df_pre98_2)

#design1_plus_estimands22 <- pop_pre98_2 + estimand22
#kable(estimand1(df_pre98_2), caption = "Estimands 22")

#design_full22 <- design1_plus_estimands22 +   estimator22

#run_design(design_full22)
```

All data and RMD file are uploaded in the following github repository: <https://github.com/mjkim12/Preanalysis>

# The Appendix

Here is the code appendix.

```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=60)}

```

# References
